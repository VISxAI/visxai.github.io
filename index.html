<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>7th VISxAI Workshop at IEEE VIS 2024</title>
    <link rel="stylesheet" href="node_modules/bootswatch/dist/sandstone/bootstrap.css">

    <link rel="stylesheet" href="styles.css">

    <link href="https://fonts.googleapis.com/css?family=IBM+Plex+Mono|IBM+Plex+Sans" rel="stylesheet">

    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
        integrity="sha256-3edrmyuQ0w65f8gfBsqowzjJe2iM6n0nKciPUp8y+7E=" crossorigin="anonymous"></script>
    <script src="node_modules/bootstrap/js/dist/util.js"></script>
    <script src="node_modules/bootstrap/js/dist/collapse.js"></script>

    <!-- Share card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@visxai" />
    <meta name="twitter:creator" content="@visxai" />
    <meta property="og:url" content="http://visxai.io" />
    <meta property="og:title" content="Workshop on Visualization for AI Explainability" />
    <meta property="og:description"
        content="The role of visualization in artificial intelligence (AI) gained significant attention in recent years. With the growing complexity of AI models, the critical need for understanding their inner-workings has increased. Visualization is potentially a powerful technique to fill such a critical need. The goal of this workshop is to initiate a call for 'explainables' / 'explorables' that explain how AI techniques work using visualization. We believe the VIS community can leverage their expertise in creating visual narratives to bring new insight into the often obfuscated complexity of AI systems."/>
    <meta property="og:image" content="http://visxai.github.io/img/share.png" />
</head>

<body>

    <nav class="navbar navbar-expand-lg navbar-light bg-light">
        <a class="navbar-brand" href="/"><span class="vxa">VISxAI</span></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarColor03"
            aria-controls="navbarColor03" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarColor03">
            <ul class="navbar-nav mr-auto">
                <li class="nav-item">
                    <a class="nav-link" href="submit.html">SUBMIT</a>
                </li>
                <li class="nav-item">
                <a class="nav-link" href="#program">Program</a>
            </li>
                <li class="nav-item">
                    <a class="nav-link" href="#dates">Dates</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#call">CFP</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#hall-of-fame">Hall of Fame</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#orga">Organizers</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#pc">PC</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="2023.html">2023</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="2022.html">2022</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="2021.html">2021</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="2020.html">2020</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="2019.html">2019</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="2018.html">2018</a>
                </li>
            </ul>
        </div>
    </nav>


    <div class="container" style="margin-top: 12pt;">

        <div class="float-right">

            <!--<img src="img/logo.png" height="70"/>-->
            <img src="img/logo_v2.png" height="70" />
        </div>
        <!--<div style="position: absolute; right:5px;">-->
        <!--</div>-->

        <h2>7<sup>th</sup> Workshop on <br> <b>Visualization for AI Explainability</b></h2>
        <p>October 13, 2024 at IEEE VIS in St. Pete Beach, Florida</p>
        
        <!-- <p class="text-center" style="font-size: 14pt;">
        <b>PROGRAM IS ONLINE. <a href="program.html"> CLICK HERE !!!</a> </b>
    </p> -->

        <p>
            The role of visualization in artificial intelligence (AI) gained
            significant attention in recent years. With the growing complexity of AI
            models, the critical need for understanding their inner-workings has
            increased. Visualization is potentially a powerful technique to fill
            such a critical need.
        </p>
        <p>
            The goal of this workshop is to initiate a call for <i>"explainables" / "explorables"</i> that
            explain how AI techniques work using visualization. We believe the VIS
            community can leverage their expertise in creating visual narratives to
            bring new insight into the often obfuscated complexity of AI systems.

        </p>


        <!-- <p class="text-center" style="font-size: 14pt;"> -->
        <!-- <b>PROGRAM IS ONLINE. <a href="program.html"> CLICK HERE !!!</a> </b> -->
        <!-- </p> -->

        <p class="text-center">

            <img class="img-fluid" src="img/examples-2024.png">
            <div class="figure-caption">Example interactive visualization articles that explain general concepts and communicate experimental insights when playing with AI models.
            (a) <a href="https://distill.pub/2019/visual-exploration-gaussian-processes/" target="_blank">A Visual Exploration of Gaussian Processes</a> by Görtler, Kehlbeck, and Deussen (<a href="https://visxai.io/2018">VISxAI 2018</a>);
            (b) <a href="https://pair.withgoogle.com/explorables/fill-in-the-blank/" target="_blank">What Have Language Models Learned?</a> by Adam Pearce (<a href="https://visxai.io/2021">VISxAI 2021</a>);
            (c) <a href="https://theo-jaunet.github.io/MemoryReduction/" target="_blank">What if we Reduce the Memory of an Artificial Doom Player?</a> by Jaunet, Vuillemot, and Wolf (<a href="https://visxai.io/2019">VISxAI 2019</a>);
            (d) <a href="https://k-means-explorable.vercel.app/" target="_blank">K-Means Clustering: An Explorable Explainer</a> by Yi Zhe Ang (<a href="https://visxai.io/2022">VISxAI 2022</a>);
            (e) <a href="https://tiga1231.github.io/umap-tour/" target="_blank">Comparing DNNs with UMAP Tour</a> by Li and Scheidegger (<a href="https://visxai.io/2020">VISxAI 2020</a>);
            (f) <a href="https://www.cs.brandeis.edu/~dylan/pac_learning/" target="_blank">PAC Learning Or: Why We Should (and Shouldn't) Trust Machine Learning </a> by Cashman (<a href="https://visxai.io/2023">VISxAI 2023</a>);
            (g) <a href="http://formafluens.io/client/mix10.html">FormaFluens Data Experiment</a> by Strobelt, Phibbs, and Martino.
            (h) <a href="https://idyll.pub/post/visxai-dimensionality-reduction-1dbad0a67a092b007c526a45/">The Beginner's Guide to Dimensionality Reduction</a> by Conlen and Hohman (<a href="https://visxai.io/2018">VISxAI 2018</a>).
            </div>
        </p>

        <h2 id="dates">Important Dates</h2>
        <pre>
<s>July 30, 2024</s> August 06, 2024, anywhere: Submission Deadline
<s>September 10, 2024:</s> Author Notification
<s>October 1, 2024:</s> Camera Ready Deadline
<b>October 13, 2024 - Morning Session (ET)</b>
    </pre>

<h2 id="program">Program Overview</h2>
<!-- <p>Coming soon!</p> -->
<p>
    All times in ET (UTC -5).
    <!-- <br> -->
    <!-- <br>→ <a href="calendar/VISxAI 2023.ics">Add VISxAI 2024 to your calendar!</a> -->


</p>

<table style="padding: 5pt;">
    <tr>
        <td class="schedule">8:30am</td>
        <td><b>Welcome from the Organizers</b></td>
    </tr>
    <tr>
        <td></td>
        <td><b>Session I (75 minutes)</b>
    </tr>
    <tr>
        <td class="schedule">8:35 -- 9:15</td>
        <td><b>Opening Keynote: David Bau - <a href="https://x.com/davidbau" target="_blank">@davidbau</a></b>
            <br>
            <b>Resilience and Human Understanding in AI</b>
            <br>
            What is the role of human understanding in AI?  As increasingly massive AI systems are deployed into an unpredictable and complex world, interpretability and controllability are the keys to achieving resilience. We discuss results in understanding and editing large-scale transformer language models and diffusion image synthesis models, and how these are part of an emerging research agenda in interpretable generative AI. Finally, we talk about the concentration of power that is emerging due to the scaling up of large-scale AI, and the kind of infrastructure that will be needed to ensure broad and democratized human participation in the future of AI.
        </td>
    </tr>

    <tr>
        <td class="schedule">9:15 -- 9:45</td>
        <td><b>Lightning Talks I</b>
            
            <br>
            <a href="https://pair.withgoogle.com/explorables/patchscopes/">
                Can Large Language Models Explain Their Internal Mechanisms?
            </a>
            -- Nada Hussein, Asma Ghandeharioun, Ryan Mullins, Emily Reif, Jimbo Wilson, Dr. Nithum Thain, Dr Lucas Dixon
            <br>
            <a href="https://yizhe-ang.github.io/matrix-explorable/">
                The Matrix Arcade: A Visual Explorable of Matrix Transformations
            </a>
            -- Yi Zhe Ang
            <br>
            <a href="visexplain.com">
                Explaining Text-to-Command Conversational Models
            </a>
            -- Petar Stupar, Prof. Dr. Gregory Mermoud, Jean-Philippe Vasseur
            <br>
            <a href="http://talktoranker.njitvis.com/">
                TalkToRanker: A Conversational Interface for Ranking-based Decision-Making
            </a>
            -- Conor Fitzpatrick, Jun Yuan, Aritra Dasgupta
            <br>
            <a href="https://murphyka.github.io/information_explorable/">
                Where is the information in data?
            </a>
            -- Kieran Murphy, Dani S. Bassett
            <br>
            <a href="https://explainability-vit.ivia.ch/">
                Explainability Perspectives on a Vision Transformer: From Global Architecture to Single Neuron
            </a>
            -- Anne Marx, Yumi Kim, Luca Sichi, Diego Arapovic, Javier Sanguino, Rita Sevastjanova, Mennatallah El-Assady
        </td>
    </tr>
    <tr>
        <td class="schedule">9:45 -- 10:15</td>
        <td><b>Break</b></td>
    </tr>
    <tr>
        <td></td>
        <td><b>Session II (75 minutes)</b>
    </tr>
    <tr>
        <td class="schedule">10:15 -- 10:45</td>
        <td><b>Lightning Talks II</b>
            <br>
            <a href="https://elanapearl.github.io/blog/2024/the-illustrated-alphafold/">
                The Illustrated AlphaFold
            </a>
            -- Elana P Simon, Jake Silberg
            <br>
            <a href="https://cchen-vis.github.io/Narrative-Viz-for-Neural-Network-Robustness/">
                A Visual Tour to Empirical Neural Network Robustness
            </a>
            -- Chen Chen, Jinbin Huang, Ethan M Remsberg, Zhicheng Liu
            <br>
            <a href="https://visxai-aml.vercel.app/">
                Panda or Gibbon? A Beginner's Introduction to Adversarial Attacks
            </a>
            -- Yuzhe You, Jian Zhao
            <br>
            <a href="https://visual-intelligence-umn.github.io/GNN-101/">
                What Can a Node Learn from Its Neighbors in Graph Neural Networks?
            </a>
            -- Yilin Lu, Chongwei Chen, Matthew Xu, Qianwen Wang
            <br>
            <a href="https://www.explainprompt.com">
                ExplainPrompt: Decoding the language of AI prompts
            </a>
            -- Shawn Simister
            <br>
            <a href="https://visualizing-interpretable-model.vercel.app">
                Inside an interpretable-by-design machine learning model: enabling RNA splicing rational design
            </a>
            -- Mateus Silva Aragao, Shiwen Zhu, Nhi Nguyen, Alejandro Garcia, Susan Elizabeth Liao
        </td>
    </tr>
    <tr>
        <td class="schedule">10:45 -- 11:30</td>
        <td><b>Closing Keynote: Adam Pearce - <a href="https://twitter.com/adamrpearce" target="_blank">@adamrpearce</a></b>
            <br>
            <b>Why Aren't We Using Visualizations to Interact with AI?</b>
            <br>
            Well-crafted visualizations are the highest bandwidth way of downloading information into our brains. As complex machine learning models become increasingly useful and important, can we move beyond mostly using text to understand and engage with them?
        </td>
    </tr>
    <tr>
        <td class="schedule">11:30am</td>
        <td><b>Closing</b></td>
    </tr>
</table>

    <br>

        <h2 id="call">Call for Participation</h2>

        <!-- <p><strong>SUBMISSION CLOSED</strong></p> -->

        <!-- <p> -->
            <!-- To make our work more accessible to the general audience, we are soliciting submissions in a novel format:
            blog-style posts and jupyter-like notebooks. In addition we also accept position papers in a more
            traditional form.

            Please contact us, if you want to submit a original work in another format. Email: <a
                href="mailto:orga.visxai@gmail.com">orga.visxai at gmail.com</a> -->
        <!-- </p> -->

        <div class="submit-button">
            <a href="/submit.html">Submission instructions</a>
        </div>
        <br>

        <p>
            Explainable submissions (e.g., interactive articles, markup, and notebooks) are the core element of the workshop, as this
            workshop aims to be a platform for explanatory visualizations focusing
            on AI techniques.
        </p>
        <p>
            Authors have the freedom to use whatever templates and formats they like. However, the narrative has to be
            visual and interactive, and walk readers through a keen understanding on the ML technique or application.
            Authors may wish to write a <a href="https://distill.pub">Distill-style</a> blog post (format), interactive
            <a href="https://idyll-lang.org/">Idyll</a> markup, or a <a href="http://jupyter.org">Jupyter</a> or <a
            href="https://beta.observablehq.com/">Observable</a> notebook that integrates code, text, and
            visualization to tell the story.
        </p>

        <p>
            Here are a few examples of visual explanations of AI methods in these types of formats:
            <ul>
                <li>[interactive article]
                    <a href="https://distill.pub/2019/visual-exploration-gaussian-processes/" target="_blank">A Visual Exploration of
                        Gaussian Processes</a>
                </li>
                <li>[interactive article]
                    <a href="https://distill.pub/2017/momentum/" target="_blank">Why Momentum Really Works</a>
                </li>
                <li>[interactive article]
                    <a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/" target="_blank">A Visual Introduction to Machine Learning</a>
                </li>
                <li>[interactive article]
                    <a href="http://formafluens.io/client/mix10.html" target="_blank">Art-Inspired Data Experiments on Neural Network Model Decay</a>
                </li>
                <li>[interactive article]
                    <a href="https://research.google.com/bigpicture/attacking-discrimination-in-ml/" target="_blank">Attacking Discrimination with Smarter Machine Learning</a>
                </li>
                <li>[markup]
                    <a href="https://parametric.press/issue-01/the-myth-of-the-impartial-machine/" target="_">The Myth of the Impartial Machine</a>
                </li>
                <li>[markup]
                    <a href="https://idyll.pub/post/visxai-dimensionality-reduction-1dbad0a67a092b007c526a45/" target="_">The Beginner's Guide to Dimensionality Reduction</a>
                </li>
                <li>[notebook]
                    <a href="https://beta.observablehq.com/@nstrayer/t-sne-explained-in-plain-javascript" target="_blank">t-SNE Explained in Plain JavaScript</a>
                </li>
                <li>[notebook]
                    <a href="https://observablehq.com/@nsthorat/how-to-build-a-teachable-machine-with-tensorflow-js?collection=@observablehq/explorables" target="_blank">How to build a Teachable Machine with TensorFlow.js</a>
                </li>
                <li>[notebook]
                    <a href="http://nbviewer.jupyter.org/github/agconti/kaggle-titanic/blob/master/Titanic.ipynb" target="_blank">Titanic Machine Learning from Disaster</a>
                </li>
            </ul>

        </p>

        <p>
            While these examples are informative and excellent, we hope the
            Visualization & ML community will think about ways to creatively expand on
            such foundational work to explain AI methods using novel interactions
            and visualizations often present at IEEE VIS.
            Please contact us, if you want to submit a original work in another
            format. Email: <a href="mailto:orga.visxai@gmail.com">orga.visxai (at) gmail.com</a>.
        </p>
        <!-- <p>
            Our workshop will be hybrid. We encourage and accept submissions for those who cannot travel to VIS in person.
        </p> -->
        <p>
            Note: We also accept more traditional papers that accompany an explainable.
            Be aware that we require that the explainable must stand on its own.
            The reviewers will evaluate the explainable (and might chose to ignore the paper).
        </p>



        <h2 id="hall-of-fame">Hall of Fame</h2>
        Each year we award Best Submissions and Honorable Mentions. <i>Congrats to our winners!</i>
        <br><br>

        <h5>VISxAI 2023</h5>
        <ul>
            <li>
                <a href="https://www.cs.brandeis.edu/~dylan/pac_learning/">
                    PAC Learning Or: Why We Should (and Shouldn't) Trust Machine Learning
                </a>
                -- Dylan Cashman
            </li>
            <li>
                <a href="https://jku-vds-lab.github.io/amumo">
                    Understanding and Comparing Multi-Modal Models
                </a>
                -- Christina Humer, Vidya Prasad, Marc Streit, Hendrik Strobelt
            </li>
            <li>
                <a href="https://pair.withgoogle.com/explorables/grokking/">
                    Do Machine Learning Models Memorize or Generalize?
                </a>
                -- Adam Pearce, Asma Ghandeharioun, Nada Hussein, Nithum Thain, Martin Wattenberg, Lucas Dixon
            </li>
        </ul>

        <h5>VISxAI 2022</h5>
        <ul>
            <li>
                <a href="https://k-means-explorable.vercel.app/">
                    K-Means Clustering: An Explorable Explainer
                </a>
                -- Yi Zhe Ang
            </li>
            <li>
                <a href="https://uvasrg.github.io/poisoning/">
                    Poisoning Attacks and Subpopulation Susceptibility
                </a>
                -- Evan Rose, Fnu Suya, David Evans
            </li>
        </ul>

        <h5>VISxAI 2021</h5>
        <ul>
            <li>
                <a href="https://pair.withgoogle.com/explorables/fill-in-the-blank/">
                    What Have Language Models Learned?
                </a>
                -- Adam Pearce
            </li>
            <li>
                <a href="http://www.cs.umd.edu/~amin/apps/visxai/sonification/">
                    Feature Sonification: An investigation on the features learned for Automatic Speech Recognition
                </a>
                -- Amin Ghiasi, Hamid Kazemi, W. Ronny Huang, Emily Liu, Micah Goldblum, Tom Goldstein
            </li>
        </ul>

        <h5>VISxAI 2020</h5>
        <ul>
            <li>
                <a href="https://tiga1231.github.io/umap-tour/">
                    Comparing DNNs with UMAP Tour
                </a> -- Mingwei Li and Carlos Scheidegger
            </li>
            <li>
                <a href="https://www.pewresearch.org/interactives/how-does-a-computer-see-gender/">
                    How Does a Computer "See" Gender?
                </a> -- Stefan Wojcik, Emma Remy, and Chris Baronavski
            </li>
        </ul>

        <h5>VISxAI 2019</h5>
        <ul>
            <li>
                <a href="https://theo-jaunet.github.io/MemoryReduction/">
                    What if we Reduce the Memory of an Artificial Doom Player?
                </a> -- Theo Jaunet, Romain Vuillemot, and Christian Wolf
            </li>
            <li>
                <a href="https://qnkxsovc.gitlab.io/prob-vis/">
                    Statistical Distances and Their Implications to GAN Training
                </a> -- Max Daniels
            </li>
            <li>
                <a href="https://mybinder.org/v2/gh/KrishnaswamyLab/visualization_selection/master?filepath=Selecting_the_right_tool_for_the_job.ipynb">
                    Selecting the right tool for the job: a comparison of visualization algorithms
                </a> -- Daniel Burkhardt, Scott Gigante, and Smita Krishnaswamy
            </li>
        </ul>

        <h5>VISxAI 2018</h5>
        <ul>
            <li>
                <a href="https://www.jgoertler.com/visual-exploration-gaussian-processes/">
                    A Visual Exploration of Gaussian Processes
                </a> -- Jochen Görtler, Rebecca Kehlbeck and Oliver Deussen
            </li>
            <li>
                <a href="https://idyll.pub/post/visxai-dimensionality-reduction-1dbad0a67a092b007c526a45/">
                    The Beginner's Guide to Dimensionality Reduction
                </a> -- Matthew Conlen and Fred Hohman
            </li>
            <li>
                <a href="https://roadsfromabove.netlify.com/">
                    Roads from Above
                </a> -- Greg More, Slaven Marusic and Caihao Cui
            </li>
        </ul>

        <!-- <p> <strong>SUBMISSION CLOSED</strong></p> -->


        <h2 id="orga">Organizers <span style="font-size: small">(alphabetic)</span>
        </h2>
        <p>
            Alex Bäuerle - Axiom Bio<br />
            Angie Boggust - Massachusetts Institute of Technology<br />
            Fred Hohman - Apple<br />
        </p>

        <h5>Steering Committee</h5>
        <p>
            Adam Perer - Carnegie Mellon University<br />
            Hendrik Strobelt - MIT-IBM Watson AI Lab<br />
            Mennatallah El-Assady - ETH AI Center<br />
        </p>

        <h2 id="pc">Program Committee and Reviewers</h2>
        <p>
            Jane Adams<br/>
            Camelia D. Brumar<br/>
            Jaegul Choo<br/>
            Brandon Duderstadt<br/>
            Angus Forbes<br/>
            Seongmin Lee<br/>
            Katelyn Morrison<br/>
            Rita Sevastjanova<br/>
            Venkatesh Sivaraman<br/>
            James Wexler<br/>
            Catherine Yeh<br/>
            Tim Barz-Cech<br/>
            Yuexi Chen<br/>
            Aeri Cho<br/>
            Bhavana Doppalapudi<br/>
            Jianben He<br/>
            Sichen Jin<br/>
            Panfeng Li<br/>
            Tong Li<br/>
            Huyen N. Nguyen<br/>
            Haowei Ni<br/>
            Yu Qin<br/>
            Rubab Zahra Sarfraz<br/>
            Johanna Schmidt<br/>
            Ryan Yen<br/>
        </p>


        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-119596896-1"></script>
        <script>
            window.dataLayer = window.dataLayer || [];

            function gtag() { dataLayer.push(arguments); }

            gtag('js', new Date());

            gtag('config', 'UA-119596896-1');
        </script>


    </div>


</body>

</html>
